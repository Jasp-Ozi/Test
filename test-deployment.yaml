apiVersion: apps/v1
kind: Deployment
metadata:
    name: web-app
    labels:
        app: web-app
spec:
    replicas: 4
    selector:
      matchlabels:
      app: web-app
    template:
      metadata:
        labels:
            app: web-app
    spec:
      containers:
      - name: web-app-containers
        image: web-app-containers:latest    # использую latest версию образа. Но в продакшене лучше указывать точную версию. Не всегда последний образ
        resources:
          requests:
            memory: "128Mi"
            cpu: "500m" # задал 0.1 CPU для одного контейнера, если учитывать что на 1 поде находиться 1 контейнер, то при минимальной нагрузке будет использоваться 1 под
          limits:         #P.S. Я передумал и поставил 500m. Так как ниже я назначаю горизонтальном масштабировании и 0.05 CPU слишком мало. Меньше чем минимальная нагрузка в задаче. Что явялется вообще неправильным вариантом. Да и ставить минимальные ресурсы когда по условию в среднем 0.1 и выше такое себе 
            memory: "128Mi"
            cpu: "1"
        startupProbe: # Можно использовать readinessProbe и livenessProbe, но как я понял, использовать livenessProbe не лучшая затея. Если приложение будет нагруженно ночью, есть шанс, что из-за таймаутов, livenessProbe может перестать работать и перезапустит все контейнеры. А там уже что будет то будет
          httpGet:                        # Если использовать livenessProbe то можно использовать лимиты приложения на запросы, тем самым выделить 1 только под эту проверку. Но опять, же зависит от приложения
            path: /
            port: 80
          initialDelaySeconds: 15 # Поставил 15 сек. из-за того для приложения требуется 10 секунд максимум для инициализации. Меньше 10 секунд ставить плачевно. Внешние проверки лучше не делать.
          periodSeconds: 15
          failureThreshold: 20 # Поставил 20 проверок перед признанием кантейнера не леквидным, возможно, нужно больше, но у меня не достаточно опыта анализировать это
      affinity:   # Отвечает за распределение подов на нодах. Я выбрал данный способ, так как он мне показался довольно универсальным по сравнению с NodeSelector и Taints (хотя последний, это как я понимаю, противоположенность Affinity)
        nodeAffinity:
          preferredDuringSchedulingIgnoredDuringExecution: # Выбрал данный класс, как оптимальный для данного кластера. Да и по мне проще кажется, когда поды размещаются сначала по требованию Affiniti, но если не получается scheduler разместит их как получится. Понятно, что для прода, нужно думать и использовать данный способ возможно не оптимально. Но, возможно использовать requiredDuringSchedulingIgnoredDuringExecution было бы использовать тут тоже. Так как у нас 5 нод и 4 пода и не должно произойти такой вероятности, что поды не смогут разместиться и и какой то из них застранят в статусе Pending
          - weight: 1 
            preference:
              matchExpressions:
              - key: topology.kubernetes.io/zone # Обычное условие на зону размещения
                operator: In
                values:
                - zone-1
                - zone-2
                - zone-3
        podAntiAffinity: # В данном случае это обязательно. Я не должен размещать поды с одной меткой на одной ноде
           preferredDuringSchedulingIgnoredDuringExecution:      # А здесь данный класс будет уместен, так как нам не нужно чтобы они рандомно разместились вместе на ожной ноде
           - weight: 1
             podAffinityTerm:
              labelSelector:
                matchExpressions:   
                - key: app
                  operator: In
                  values:
                  - web-app
              topologyKey: kubernetes.io/hostname

apiVersion: autoscaling/v1
kind: HorizontalPodAutoscaler # я решил использовать данный контроль для автомасштабирования так как ночью запросов на порядок меньше и пусть он масштабирует на основе утилизации CPU. Я честно не до конца понял как работает данный контролер
metadata:
  name: web-app-hpa      # задал имя для горизантального масштабирования
spec:
  scaleTargetRef: # задаем ссылка на цель масштабирования, в частности на deployment
    apiVersion: apps/v1
    kind: Deployment
    name: web-app # имя нашего deployment
  minReplicas: 2 #   Задал 2 пода минимальным, так как по условию вы просите максимально отказоустойчевый deployment. А так, можно выбрать и 1 для простых приложений, где не так кретична отказаустоичевость
  maxReplicas: 4 # Ну тут логично, что максимальное значени в момент нагрузки. У нас 4 пода
  targetCPUUtilizationPercentage: 50 # По мне так оптимальный вариант. Но можно и поиграться с параметрами


